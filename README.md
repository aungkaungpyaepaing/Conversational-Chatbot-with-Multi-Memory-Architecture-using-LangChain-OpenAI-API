<h1>ğŸ“„ Description</h1>


This project demonstrates a conversational AI chatbot built using LangChain and OpenAI's API, enhanced with two types of memory:

ğŸ§  ConversationBufferMemory: preserves the raw message history.

ğŸ§  ConversationSummaryMemory: maintains a dynamic summary of the conversation.

These memories are combined using CombinedMemory to give the LLM a richer context: raw user interactions and a concise abstract. The chatbot responds with improved coherence, continuity, and awareness of long-term context.




<h1>ğŸ› ï¸ Features</h1>


ğŸ’¬ OpenAI GPT-based chatbot (ChatOpenAI)

ğŸ“š Multi-memory support (CombinedMemory)

ğŸ“– Prompt engineering with dynamic input injection

ğŸ§ª Interactive examples in Jupyter Notebook (.ipynb)

âœ… Modular, beginner-friendly, and production-ready



<h1>ğŸ§  How Memory Works</h1>


ConversationBufferMemory helps the LLM remember the latest turns verbatim.

ConversationSummaryMemory uses a language model to summarize the conversation progressively.

CombinedMemory feeds both to the prompt template to enable deep reasoning.
